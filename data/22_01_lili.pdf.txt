Language Learning & Technology 
ISSN 1094-3501 
February 2018, Volume 22, Issue 1 
pp. 27–41 
LANGUAGE TEACHING AND TECHNOLOGY FORUM  
 
 
Copyright © 2018 Jinrong Li & Mimi Li 
 
 
Turnitin and peer review in 
ESL academic writing classrooms 
Jinrong Li, Georgia Southern University 
Mimi Li, Texas A&M University-Commerce 
Abstract 
Despite the benefits of peer review, there are still challenges that need to be addressed to make it more 
effective for L2 students. With the development of technology, computer-mediated peer review has 
captured increasing attention from L2 writing researchers and instructors. While Turnitin is known for its 
use in detecting plagiarism, its newly developed module, PeerMark, aims to facilitate peer review. In this 
article, we share our experience of using Turnitin for peer review in an ESL academic writing course and 
discuss its advantages, its limitations, and how different features of PeerMark may be used to address 
some of the challenges identified in previous research on peer review in the L2 writing classroom. 
Throughout a semester, the students were required to complete three peer review tasks through Turnitin. 
Based on the instructor’s experience and the students’ reports, we found that Turnitin could help shift 
students’ attention from local to global issues in writing, scaffold students in their effort to provide more 
helpful comments and to make connections between specific suggestions and holistic advice for writing, 
and facilitate classroom management during peer review. 
Keywords: Writing, Feedback, Computer-Mediated Communication, Instructional Context 
Language(s) Learned in this Study: English 
APA Citation: Li, J., & Li, M. (2018). Turnitin and peer review in ESL academic writing classrooms. 
Language Learning & Technology, 22(1), 27–41. https://dx.doi.org/10125/44576 
Introduction 
Decades of research on peer review have provided theoretical rationale and empirical evidence in favor of 
its benefits for both first language (L1) and second language (L2) student writers (Chen, 2016; Flower & 
Hayes, 1981; Ho & Savignon, 2007; Hyland & Hyland, 2006; Zamel, 1982). Specifically, peer review can 
help engage students in the process of writing and revision (Miao, Badger, & Zhen, 2006) and enhance 
students’ understanding of audience and purpose (Ho & Savignon, 2007; Lee, 2015; Rollinson, 2005). It 
also heightens students’ sense of learning communities (Ferris, 2003; Ferris & Hedgcock, 2005) and 
contributes to the development of L2 students’ linguistic and writing competence (Hedgcock & Lefkowitz, 
1992; Lam, 2013; Lockhart & Ng, 1995; Min, 2006). 
However, several challenges have been identified in peer review conducted in face-to-face settings (Ferris 
& Hedgcock, 2005; Kim, 2015; Leki, 1990; Liu & Hansen, 2002), and researchers have started to explore 
how technology can facilitate peer review (e.g., Chen, 2016; DiGiovanni & Nagaswami, 2001; Liang, 
2010). Microsoft Word (AbuSeileek & Abualsha’r, 2014; Liu & Sandler, 2003), synchronous chatting 
(Chang, 2012), and bulletin-board posting (Guardado & Shi, 2007) have all been found to be helpful. A 
recent example of growing interests in using technology to facilitate peer review is the development of 
Turnitin. Although Turnitin has been used primarily to ensure originality in students’ written work 
(Buckley & Cowap, 2013; Penketh & Beaumont, 2014), its new module, PeerMark, designed to help 
facilitate peer review, is largely unexplored. Therefore, in this article, we share our experience of using 
Turnitin for peer review in an ESL academic writing course and discuss how different features of 
PeerMark may be used to address some of the challenges identified in previous research on peer review 
28 Language Learning & Technology 
 
among L2 students. 
Challenges for Peer Review 
Research suggests a number of barriers to effective peer review among L2 students. A major issue is that 
L2 students may focus heavily on local issues and neglect global issues in writing and revision (Nelson & 
Carson, 1998; Tsui & Ng, 2000). In their study of peer review among 169 students, McGroarty and Zhu 
(1997) identified three types of peer feedback: global feedback that emphasizes idea development, 
audience, purpose, and organization; local feedback that stresses vocabulary, grammar, and punctuation; 
and evaluative feedback that expresses overall evaluation. Studies have shown that many L2 student 
writers tend to focus on local issues due to their primary concern for the use of a L2 or their lack of 
experience in providing effective feedback (e.g., Tsui & Ng, 2000). Moreover, student comments may be 
vague, unhelpful, or inaccurate (Nilson, 2003), because they might not have enough experience as a 
reviewer or because they might have difficulties articulating problems and suggestions (Kim, 2015; Leki, 
1990; Mendonca & Johnson, 1994). These language problems may contribute to the students’ lack of 
confidence in the validity, reliability, and usefulness of their feedback to their peers and the feedback they 
receive from peers (Sengupta, 1998; Tang & Tithecott, 1999; Tsui & Ng, 2000; Wang, 2014). 
Furthermore, due to cultural differences and possibly a lack of L2 rhetorical schemata, many L2 students 
may have inconsistent or inaccurate expectations about the content and structure of peers’ texts and 
provide “counterproductive feedback” (Ferris & Hedgcock, 2005, p. 227). 
There are also concerns of potential communication problems during interactions in face-to-face peer 
review due to pronunciation or listening comprehension issues. Communication problems may also occur 
when comments are too direct and are perceived as overly critical of, or even hostile to others’ writing 
(Ferris & Hedgcock, 2005), and when students from different cultures have different expectations and 
conceptualizations about the role of feedback during revision (Silva, 1997; Zhang, 1995). 
Moreover, classroom management is critical for running successful peer review sessions (Ferris & 
Hedgcock, 2005), particularly when considering grouping strategies. There is no consensus regarding 
whether or not group members should be of the same or different proficiency levels or if the groups 
should be static or dynamic (Chang, 2016), but when making these decisions, a frequently occurring 
classroom management issue is how the students will exchange their papers. Traditionally, students bring 
printed copies of their papers to class, and the instructor has to cope with the possibility of students not 
coming to class or failing to bring their papers to class. Another issue is a lack of sustained discussion: 
when provided with peer review guidelines or worksheets, many students focus on answering the 
instructor’s prompts and are not motivated to exchange ideas with one another regarding the quality of the 
papers (Ferris & Hedgcock, 2005). Additionally, different students and groups work at different paces, 
and thus, the instructor usually needs to prepare some follow-up activities for students who complete the 
review task faster than others. 
A set of guiding principles for effective peer review has been proposed that emphasizes the importance of 
instructor preparation and student training before the peer review, the structure of the peer review activity, 
the instructor’s monitoring of students’ progress, and guided reflection after the peer review (Hansen & 
Liu, 2005). These ideas are echoed by Kim (2015) who highlighted the need to provide L2 students with 
linguistic resources to help them articulate their comments and to reduce their anxiety. Design features of 
Turnitin and its embedded tools seem to be able to offer such scaffolding to help students learn to provide 
effective written feedback, in addition to improve their capacities to assist instructors plan and manage the 
peer review activity. In the following sections, we report our exploration of the potential use of Turnitin 
for peer review, and discuss the extent to which incorporating this new platform may address the 
challenges facing instructors and students during peer review. 
Jinrong Li and Mimi Li 29 
 
Methods 
Context and Participants 
This study was carried out in spring 2016 in an English as a second language (ESL) academic writing 
course at a medium-sized public university in the United States. The primary objective of this course was 
to help strengthen undergraduate L2 students’ academic writing skills and linguistic competence. One of 
the authors taught this course and used They Say, I Say: The Moves That Matter in Academic Writing as 
the textbook (Graff & Birkenstein, 2010). Throughout the semester, the students were required to 
complete an analytical summary, a comparative analysis, and an argument synthesis. For each assignment, 
the students were asked to submit a rough draft, participate in peer review, and revise and submit a final 
draft. The instructor provided feedback on the rough draft, and graded the final draft. 
Of the 15 students enrolled in the class, 13 agreed to participate in the study. The participants’ L1s 
included Chinese, French, Japanese, Korean, and Spanish. Although the students varied in the length of 
and experience with learning English, their English proficiency and writing skills were considered 
comparable, because they were placed into the class based on the results of an institutional English 
placement test they took upon arrival at the university. All participants were familiar with basic word 
processing tools and the Internet, but none of them had been introduced to Turnitin or had used it in any 
other courses prior to the beginning of the study. The students were neither introduced to academic 
writing in English nor required to complete peer review in English before the start of this class. 
Setting up Peer Review Tasks 
Turnitin is an integrated tool embedded in the institutionally supported course management system, 
Desire2Learn, and peer review tasks1 were added as activities in a designated module. Throughout the 
semester, the instructor used Turnitin to facilitate three peer review sessions and offered training at the 
beginning of the semester (see Figure 1). 
 
Figure 1. Peer review tasks embedded in a module in Desire2Learn. 
To specify the requirements of the peer review, the instructor edited the settings (see Figure 2). In the 
Settings tab, the instructor first set up and edited the properties of the writing assignments and then 
specified other relevant information, such as the use of originality report and grammar checking in the 
optional settings. Originality report provided a summary of matches between the submitted paper and 
work stored in its database. Grammar checking was enabled by ETS e-rater technology, and it provided 
automated corrective feedback. The instructor then created the associated peer review tasks by selecting 
the “Yes” radio button under “Add PeerMark assignments” toward the end of the list of optional settings 
30 Language Learning & Technology 
 
(see Figure 3). Thus, the PeerMark Setup and the PeerMark Review tabs were generated (see Figure 4), 
allowing detailed instructions for the peer review tasks to be provided. 
 
Figure 2. Settings for the associated writing assignment. 
 
Figure 3. Creating peer review task for the associated writing assignment. 
Jinrong Li and Mimi Li 31 
 
 
Figure 4. The PeerMark Setup and PeerMark Reviews tabs. 
The layout of the PeerMark Setup tab is similar to that of the Settings tab (see Figure 5). This tab is where 
the instructor can adjust anonymity, decide whether or not students without a paper can participate, and 
determine if students are allowed to read all papers and reviews (see Figure 6). Additionally, the 
instructor can specify the number of papers students must review, whether or not students are allowed to 
choose the papers they review, and whether or not self-assessments of their own papers are required. In 
our study, the peer review was anonymous, students without papers could participate, and all students 
were allowed to read all papers and reviews. For all three peer review tasks, the students reviewed two 
papers randomly distributed by Turnitin. 
 
Figure 5. PeerMark Setup tab for the peer review activity. 
32 Language Learning & Technology 
 
 
Figure 6. Additional settings for the peer review activity. 
Next to the PeerMark Assignment tab is the PeerMark Questions tab (see Figure 7), where the instructor 
added guiding questions to scaffold students’ peer review in relation to the specific writing tasks. The 
guiding questions were all free response questions.2 Lastly, the instructor can specify group membership 
in the distribution tab if random assignment is not the preferred strategy (see Figure 8). 
 
Figure 7. Adding questions to guide peer review. 
Jinrong Li and Mimi Li 33 
 
 
Figure 8. Specifying group membership for the peer review activity. 
The Peer Review Tasks: Students’ Angle 
To start reviewing a paper, students need to go to the PeerMark Reviews tab, click on “Write Reviews” 
dropdown menu, and then click on “Start a review” (see Figure 9). A new window opens up in which the 
student can see the reviewer’s work space (see Figure 10). The interface consists of a larger column on 
the left where the paper to be reviewed is displayed and a smaller column on the right where the reviewer 
can switch between questions and comments. The Questions tab contains all the guiding questions for the 
review and text boxes where the reviewer can type in their responses.3 The Comments tab displays copies 
of reviewer comments and helps students keep track of the comments. To add comments or to mark the 
paper directly, the students can access the software’s commenting tools and composition marks (a total of 
nine options) by clicking on the “Tools” button in the upper-left corner of the screen. 
 
Figure 9. The peer review task and how to start a review. 
34 Language Learning & Technology 
 
 
Figure 10. The peer review workspace on Turnitin. 
The commenting tools allow the student to add comment bubbles or to highlight segments of the paper 
and add associated comment bubbles. Using these tools, the reviewer can mark the paper and add inline 
or margin comments directly onto the paper. The student can also easily drag and drop the composition 
marks onto the paper to help highlight and explain different issues of the paper: incorrect spelling, 
inappropriate word choice, improper citation, and a few other frequently occurring language-related and 
mechanical issues. Each composition mark comes with some pre-stored explanation of the issue it 
represents, and the user can view the explanation by simply moving the pointer over the composition 
mark. 
To read the feedback after peer review sessions, students need to go to the PeerMark Reviews tab and 
click on the highlighted green button with a check mark sign. A new window opens up for the students to 
read the reviews (see Figure 11). This interface also consists of a larger column that displays the paper 
and comments and a smaller column where the student can select reviewers, guiding questions and 
answers, and copies of comments. By clicking the first icon at the bottom of the smaller section, the 
student can choose to view comments from a specific reviewer or from all reviewers. The second icon 
with a question mark allows the student to read the reviewer’s responses to the guiding questions. By 
clicking on the third icon, the student is able to see copies of all comments and composition marks left by 
the reviewer. As shown in Figure 11, the reviewer has highlighted segments of the paper, inserted bubble 
comments, and used composition marks. 
Jinrong Li and Mimi Li 35 
 
 
Figure 11. Receiving and reading feedback from peers. 
Results and Discussion  
Turnitin and the Quality of Peer Feedback 
For this study, we collected data from archived Turnitin peer review records, questionnaires, and student 
reflections. Overall, the results suggested that Turnitin helped facilitate peer review and contributed to the 
improvement of the quality of student comments. Based on an analysis of student comments collected 
from the first and third peer review tasks, the percentage of student comments focusing on global issues 
increased from 35.6% to 71.2% (for more details, see Li & Li, 2017). The results challenge previous 
findings concerning students’ overwhelming focus on local issues in the asynchronous mode (Chang, 
2012), and show that Turnitin may have helped shift students’ attention from local to global issues. 
Previous research informs us that student training plays an important role in helping engage students in 
meaningful conversations during the peer review process and in developing students’ understanding of 
the need to focus on both global and local aspects of writing (Berg, 1999; Min, 2005; Rahimi, 2013; 
Stanley, 1992). Based on our experience and observation, we believe that Turnitin played a positive role 
in strengthening the students’ awareness of the need to focus on both global and local issues. As 
introduced above, both the review workspace and the interface documenting peer review are clearly 
divided into two sections (see Figures 10 and Figure 11). This design feature may help raise students’ 
awareness of the need to focus on both local and global issues and to help divide the review task into 
36 Language Learning & Technology 
 
different steps. Specifically, students are able to attend to local or more salient issues while reading a 
paper for the first time. At this stage, the students can use commenting tools and composition marks to 
highlight problematic segments while reading the paper. This would help build students’ confidence in 
providing feedback and allow them to have a better understanding of the paper. The students can then be 
invited to further consider and comment on global issues by responding to the assignment-tailored 
guiding questions provided by the instructor. Additionally, the guiding questions can be phrased to help 
students see the connection between a particular problem and how that problem might affect the structure 
and content development of the paper. Thus, students may better understand the significance of global 
issues and how they may be affected by local issues. 
Regarding the helpfulness of student comments, the results from our questionnaire and student reflections 
revealed that most students found the peer feedback received through Turnitin to be constructive, 
thorough, and helpful. Our questionnaire included 12 items on a 5-point Likert scale, and the perceived 
usefulness of peer feedback through Turnitin (Item 6) was high (M = 4.08, SD = 0.67). More importantly, 
the students also found the guiding questions (Item 7) and commenting tools (Item 8) to be helpful for 
peer review (M = 4.58, SD = 0.51; M = 4.08, SD = 0.90; respectively), and most of them reported that 
they were able to incorporate peer feedback into their revision (Item 11) and use the comments to 
improve their writing (Item 12; M = 3.92, SD = 0.67; M = 4.17, SD = 0.39; respectively). 
The students’ reflections further indicated that Turnitin offered scaffolding to help articulate problems 
and suggestions and thus made the feedback more helpful. Specifically, most students reported that being 
able to drag and drop different tools to highlight problems on the paper was very helpful, and that it was 
convenient and beneficial to be able to read brief explanations of an error by hovering their pointer over 
the error. One student commented on the potential of PeerMark features in this regard: 
The commenting tool made it easier to comment while you are reading the paper and it tells exactly 
where the mistake or the thing you want to comment is, so you don’t have to remember everything in 
your head until the end of the paper … I found composition marks really effective since you give 
comment and/or highlight the sentence or word that you want the writer to focus on so he knows 
exactly what you are talking about. (Post-study reflection 08) 
The quote above shows that the commenting tools and composition marks helped facilitate the review 
process for the students. It also demonstrates how the split review workspace can be used purposefully to 
encourage students to think about both specific issues and general suggestions for the improvement of the 
overall quality of the paper. 
Additionally, some students reported that reading the explanations of errors embedded in composition 
marks helped them formulate their own observations and suggestions. Although the students did not 
provide further explanations for why this might be the case, it was possible that reading the explanations 
allowed them to learn to use more accurate terms and expressions to describe issues regarding grammar 
and mechanics, such as run-on sentences. Another embedded tool, GradeMark, allowed the students to 
access and use automated corrective feedback and thus helped students recognize and articulate language-
related issues. As shown in Figure 12, some errors were highlighted with error codes, and when placing 
the pointer over the error code, the students could see an explanation of the error and access a link to a 
section of an embedded handbook that corresponded to the error. Although the students were not able to 
use this feature to check others’ papers during the peer review sessions, they commented on the benefits 
of the automated corrective feedback in helping them recognize errors in their own writing. We believe 
that highlighted errors and automated feedback can also be good examples to use in classroom activities 
or training sessions aiming to develop students’ competence and language skills as a reviewer and a writer. 
Jinrong Li and Mimi Li 37 
 
 
Figure 12. GradeMark and automated feedback embedded in Turnitin. 
Turnitin and Classroom Management Issues 
Based on our experience, Turnitin facilitated classroom management and made it easier to implement 
pedagogical strategies aimed at improving the effectiveness of peer review. First, by using Turnitin, we 
were able to quickly set up a double-blind peer review. Research shows that anonymity makes the review 
process less stressful for the reviewer and may thus result in more honest and meaningful feedback 
(DiGiovanni & Nagaswami, 2001; Guardado & Shi, 2007), allowing writers to more objectively evaluate 
reviewer feedback without the influence of reviewer identity or competence (Strijbos, Narciss, & 
Dunnebier, 2010). Our students’ reflections also showed that anonymity was highly valued during the 
peer review, and the following quote is an example: 
An advantage of the Peer review feedback provided through Turnitin is the anonymity that comes 
with it. I like that I am able to critique a peer’s work without any fear of being threatened by that 
person for criticisms. It is a small class and I do not want to go about with people thinking I hurt their 
feelings about their ways of writing through my corrections. (Post-study reflection 12) 
Double-blind review presents logistical challenges in a face-to-face environment. In Turnitin, however, 
with anonymity set up by the instructor, the identity of the authors and reviewers is hidden from the 
students, but not from the instructor.4 
Grouping is also easier to manage in Turnitin. Depending on the needs of the class and the characteristics 
of the peer review task, the instructor can decide to have students work in pairs, small groups, or large 
groups. Research suggests that having multiple reviewers and dynamic grouping enhances students’ 
audience awareness and helps them get multiple perspectives (Chang, 2015). However, dynamic grouping 
seems to be time-consuming in the face-to-face context. With Turnitin, grouping can be done easily by 
the instructor when the peer review task is set up. Instructors can choose static grouping or dynamic 
grouping across multiple writing tasks according to their own needs, and the grouping strategies do not 
affect the procedure of peer review in the classroom. 
There are two other helpful features: (a) an option that allows students without papers to participate and 
(b) an option that allows students to read all papers or all reviews. The first option helps reduce group or 
classroom distractions when some students fail to bring their own papers. The only consequence is that 
the students who fail to submit their papers on time do not receive any peer feedback. The second option 
offers very rich resources for teaching and learning in the L2 writing classroom. In this study, the students 
were allowed to read all papers and feedback, and their reports showed that this helped them better 
understand the writing requirements, develop ideas, and plan for organization. Similar to what a student 
38 Language Learning & Technology 
 
shared in the following quote, most of our students reported that they took the opportunity to read all 
papers and reviews and benefited from this experience: 
I think that first a peer review is something efficient and useful, in the way that it permit to each 
students to read what others have written, and can give to the students new ideas and correct 
themselves. So for me Turnittin is really effective and easy to use. (Post-study reflection 01) 
In the quote above, the student felt that being able to read others’ papers and comments was particularly 
helpful for developing new ideas for her own paper. It is also likely that reading the papers and comments 
of other students may help strengthen students’ competence in providing peer feedback. 
Conclusion 
The benefits of peer review have been supported by theories and empirical studies from both L1 and L2 
research. However, there are still challenges that need to be addressed in order to make peer review more 
effective. To address some of the challenges of peer review for L2 students, we looked into the potential 
of using Turnitin as a platform for peer review in an ESL academic writing class. Throughout one 
semester, our students were required to complete three peer review tasks through Turnitin. Based on our 
experience and student reports, we found that Turnitin could offer assistance in the following three 
aspects: (a) shifting students’ attention from local to global issues, (b) scaffolding students in their effort 
to provide more specific and helpful comments and to make connections between specific suggestions 
and holistic advice for overall writing, and (c) facilitating classroom management during peer review 
sessions. 
Admittedly, there are limitations when using Turnitin as a platform for peer review. For example, a 
synchronous computer-mediated communication feature is not incorporated in the platform. Peer review 
tasks implemented on this platform are entirely written and may need to be complemented by face-to-face 
communication afterward or synchronous online communication using other programs. In addition, 
although the students were able to use the originality check and the automated corrective feedback for 
their own papers, they could not access these tools for the target paper during the review process. Turnitin 
has recently updated the module for peer review, and with increasing awareness of this platform, we hope 
future studies and pedagogical practices will offer more empirical evidence regarding its role in peer 
review. 
Notes 
1. Peer review tasks in Turnitin needed to be attached to a writing assignment, and therefore, the writing 
assignment had to be created first. 
2. It is important to note that once the peer review task was active (i.e., after the system recorded one 
student submission), no further changes could be made to the guiding questions. 
3. The minimum word limit was displayed underneath each box if specified. 
4. Other learning management systems such as Moodle allow the instructor to do the same. 
References 
AbuSeileek, A., & Abualsha’r, A. (2014). Using peer computer-mediated corrective feedback to support 
EFL learners’ writing. Language Learning & Technology, 18(1), 76–95. 
https://dx.doi.org/10125/44355  
Berg, E. C. (1999). The effects of trained peer response on ESL students’ revision types and writing 
quality. Journal of Second Language Writing, 8(3), 215–241. 
Jinrong Li and Mimi Li 39 
 
Buckley, E., & Cowap, L. (2013). An evaluation of the use of Turnitin for electronic submission and 
marking and as a formative feedback tool from an educator's perspective. British Journal of 
Educational Technology, 44(4), 562–570. 
Chang, C.-F. (2012). Peer review via three modes in an EFL writing course. Computers and Composition, 
29, 63–78. 
Chang, C. Y.-h. (2015). Teacher modeling on EFL reviewers’ audience-aware feedback and affectivity in 
L2 peer review. Assessing Writing, 25, 2–21. 
Chang, C. Y.-h. (2016). Two decades of research in L2 peer review. Journal of Writing Research, 8(1), 
81–117. 
Chen, T. (2016). Technology-supported peer feedback in ESL/EFL writing classes: A research synthesis. 
Computer Assisted Language Learning, 29(2), 365–397. 
DiGiovanni, E., & Nagaswami, G. (2001). Online peer review: An alternative to face-to-face. ELT 
Journal, 55, 263–272. 
Ferris, D. R. (2003). Responding to writing. In B. Kroll (Ed.), Exploring the dynamics of second language 
writing (pp. 119–140). Cambridge, UK: Cambridge University Press. 
Ferris, D. R., & Hedgcock, J. S. (2005). Building a community of writers: Principles of peer response. In 
D. R. Ferris & J. S. Hedgcock (Eds.), Teaching ESL Composition: Purpose, Process, and Practice 
(pp. 223–259). Mahwah, NJ: Lawrence Erlbaum Associates. 
Flower, L. S., & Hayes, J. R. (1981). A cognitive process theory of writing. College Composition and 
Communication, 32, 365–387. 
Graff, G., & Birkenstein, C. (2010). “They say I say”: The moves that matter in academic writing (2nd 
ed.). New York, NY: W. W. Norton & Company. 
Guardado, M., & Shi, L. (2007). ESL students' experiences of online peer feedback. Computers and 
Composition, 24(4), 443–461. 
Hansen, J. G., & Liu, J. (2005). Guiding principles for effective peer response. ELT Journal, 59(1), 31–38. 
Hedgcock, J., & Lefkowitz, N. (1992). Collaborative oral/aural revision in foreign language writing 
instruction. Journal of Second Language Writing, 1, 255–276. 
Ho, M.-C., & Savignon, S. J. (2007). Face-to-face and computer-mediated peer review in EFL writing. 
CALICO Journal, 24(2), 269–290. 
Hyland, K., & Hyland, F. (2006). Contexts and issues in feedback on L2 writing: An introduction. In K. 
Hyland & F. Hyland (Eds.), Feedback in second language writing: Contexts and issues (pp. 1–19). 
Cambridge, UK: Cambridge University Press. 
Kim, S. H. (2015). Preparing English learners for effective peer review in the writers' workshop. The 
Reading Teacher, 68(8), 599–603. 
Lam, R. (2013). The relationship between assessment types and text revision. ELT Journal, 67(4), 446–
458. 
Lee, M.-K. (2015). Peer feedback in second language writing: Investigating junior secondary students’ 
perspectives of inter-feedback and intra-feedback. System, 55, 1–10. 
Leki, I. (1990). Potential problems with peer responding in ESL writing classes. CATESOL Journal, 3, 5–
19. 
Li, M., & Li, J. (2017). Online peer review using Turnitin in first-year writing classes. Computers and 
Composition, 46, 21–38. 
40 Language Learning & Technology 
 
Liang, M.-Y. (2010). Using synchronous online peer response groups in EFL writing: Revision-related 
discourse. Language Learning & Technology, 14(1), 45–64. https://dx.doi.org/10125/44202   
Liu, J., & Hansen, J. G. (2002). Peer response in second language writing classrooms. Ann Arbor, MI: 
University of Michigan Press. 
Liu, J., & Sadler, R. W. (2003). The effect and affect of peer review in electronic versus traditional modes 
on L2 writing. Journal of English for Academic Purposes, 2, 193–227. 
Lockhart, C., & Ng, P. (1995). Analyzing talk in ESL peer response groups: Stances, functions, and 
content. Language Learning, 45(4), 605–655. 
McGroarty, M. E., & Zhu, W. (1997). Triangulation in classroom research: A study of peer revision. 
Language Learning, 47(1), 1–43. 
Mendonca, C., & Johnson, K. (1994). Peer review negotiations: Revision activities in ESL writing 
instruction. TESOL Quarterly, 28, 745–769. 
Miao, Y., Badger, R., & Zhen, Y. (2006). A comparative study of peer and teacher feedback in a Chinese 
EFL writing class. Journal of Second Language Writing, 15, 179–200. 
Min, H.-T. (2005). Training students to become successful peer reviewers. System, 33(2), 293–308. 
Min, H.-T. (2006). The effects of trained peer review on EFL students’ revision types and writing quality. 
Journal of Second Language Writing, 15, 118–141. 
Nelson, G., & Carson, J. (1998). ESL students’ perceptions of effectiveness of peer response groups. 
Journal of Second Language Writing, 7, 113–131. 
Nilson, L. B. (2003). Improving student peer feedback. College Teaching, 51(1), 34–38. 
Penketh, C., & Beaumont, C. (2014). ‘Turnitin said it wasn’t happy’: Can the regulatory discourse of 
plagiarism detection operate as a change artefact for writing development? Innovations in Education 
and Teaching International, 51(1), 95–104. 
Rahimi, M. (2013). Is training student reviewers worth its while? A study of how training influences the 
quality of students’ feedback and writing. Language Teaching Research, 17(1), 67–89. 
Rollinson, P. (2005). Using peer feedback in the EFL writing class. ELT Journal, 59, 23–30. 
Sengupta, S. (1998). Peer evaluation: ‘I am not the teacher’. ELT Journal, 52(1), 19–28. 
Silva, T. (1997). On the ethical treatment of ESL writers. TESOL Quarterly, 31, 359–363. 
Stanley, J. (1992). Coaching student writers to be more effective peer evaluators. Journal of Second 
Language Writing, 1, 217–233. 
Strijbos, J., Narciss, S., & Dunnebier, K. (2010). Peer feedback content and sender’s competence level in 
academic writing revision tasks: Are they critical for feedback perceptions and efficiency? Learning 
and Instruction, 20, 291–303. 
Tang, G. M., & Tithecott, J. (1999). Peer response in ESL writing. TESL Canada Journal, 16(2), 20–38. 
Tsui, A. B. M., & Ng, M. (2000). Do secondary L2 writers benefit from peer comments? Journal of 
Second Language Writing, 9(2), 147–170. 
Wang, W. (2014). Students’ perceptions of rubric-referenced peer feedback on EFL writing: A 
longitudinal inquiry. Assessing Writing, 19, 80–96. 
Zamel, V. (1982). Writing: The process of discovering meaning. TESOL Quarterly, 16, 195–209. 
Zhang, S. (1995). Reexamining the affective advantage of peer feedback in the ESL writing class. Journal 
of Second Language Writing, 4, 209–222. 
Jinrong Li and Mimi Li 41 
 
About the Authors 
Jinrong Li (PhD, Iowa State University) is an Assistant Professor in the Department of Writing and 
Linguistics at Georgia Southern University. Her research interests include computer-assisted language 
learning and L2 writing instruction and assessment. Her work has been published in Journal of Second 
Language Writing, Assessing Writing, and CALICO Journal. 
E-mail: jli@georgiasouthern.edu 
Mimi Li (PhD, University of South Florida) is an Assistant Professor in the Department of Literature and 
Languages at Texas A&M University-Commerce. Her research interests include second language writing, 
computer-assisted language learning, and English for academic/specific purposes. Her work has appeared 
in Language Learning & Technology, Computer Assisted Language Learning, Journal of Second 
Language Writing, System, and Computers & Education. 
E-mail: mimi.li@tamuc.edu 
